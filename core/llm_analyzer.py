import asyncio
from typing import List, Dict
import json
from pathlib import Path
import string

try:
    from astrbot.api import logger
except ImportError:
    import logging
    logger = logging.getLogger(__name__)
from ..core.utils import convert_content_to_string, format_relative_time, JsonParser
from ..models.analysis_result import SecretaryDecision
from .prompt_module_loader import PromptModuleLoader


class SafeFormatter(string.Formatter):
    """
    å®‰å…¨çš„å­—ç¬¦ä¸²æ ¼å¼åŒ–å™¨ï¼Œå½“å ä½ç¬¦ä¸å­˜åœ¨æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²æˆ–æŒ‡å®šçš„é»˜è®¤å€¼
    """

    def __init__(self, default_value: str = ""):
        """
        åˆå§‹åŒ–å®‰å…¨æ ¼å¼åŒ–å™¨

        Args:
            default_value (str): å½“å ä½ç¬¦ä¸å­˜åœ¨æ—¶è¿”å›çš„é»˜è®¤å€¼
        """
        self.default_value = default_value

    def get_value(self, key, args, kwargs):
        """
        è·å–å ä½ç¬¦çš„å€¼

        Args:
            key: å ä½ç¬¦çš„é”®
            args: ä½ç½®å‚æ•°
            kwargs: å…³é”®å­—å‚æ•°

        Returns:
            å ä½ç¬¦çš„å€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼
        """
        if isinstance(key, str):
            try:
                return kwargs[key]
            except KeyError:
                return self.default_value
        else:
            return string.Formatter.get_value(key, args, kwargs)


class LLMAnalyzer:
    """
    LLMåˆ†æå™¨ - æ‰§è¡Œå®æ—¶åˆ†æå’Œæ ‡æ³¨
    é‡‡ç”¨ä¸¤çº§AIåä½œä½“ç³»ï¼š
    1. è½»é‡çº§AIï¼ˆåˆ†æå‘˜ï¼‰ï¼šä½æˆæœ¬ã€å¿«é€Ÿåœ°åˆ¤æ–­æ˜¯å¦éœ€è¦å›å¤ã€‚
    2. é‡é‡çº§AIï¼ˆä¸“å®¶ï¼‰ï¼šåœ¨éœ€è¦æ—¶ï¼Œç”Ÿæˆé«˜è´¨é‡çš„å›å¤ã€‚
    """

    # ç±»çº§åˆ«çš„å¸¸é‡
    MAX_CONVERSATION_LENGTH = 50

    def __init__(
        self,
        analyzer_model_name: str,
        context,
        strategy_guide: str = None,
        config_manager=None,
    ):
        self.analyzer_model_name = analyzer_model_name
        self.context = context  # å­˜å‚¨ context å¯¹è±¡ï¼Œç”¨äºåŠ¨æ€è·å– provider
        self.strategy_guide = strategy_guide or ""  # å­˜å‚¨ç­–ç•¥æŒ‡å¯¼æ–‡æœ¬
        self.config_manager = config_manager  # å­˜å‚¨ config_manager å¯¹è±¡ï¼Œç”¨äºè®¿é—®é…ç½®
        self.is_ready = False  # é»˜è®¤è®¤ä¸ºåˆ†æå™¨æœªå°±ç»ª

        # åˆå§‹åŒ–æç¤ºè¯æ¨¡å—åŠ è½½å™¨
        self.prompt_loader = PromptModuleLoader()

        # åˆå§‹åŒ–JSONè§£æå™¨
        self.json_parser = JsonParser()

        # åŠ è½½å¤–éƒ¨ Prompt æ¨¡æ¿
        try:
            # ä½¿ç”¨ PromptModuleLoader æ„å»ºæç¤ºè¯æ¨¡æ¿
            is_reasoning_model = config_manager.is_reasoning_model if config_manager else False
            self.base_prompt_template = self.prompt_loader.build_prompt_template(is_reasoning_model)

            if self.base_prompt_template:
                self.is_ready = True
                output_type = "æŒ‡ä»¤" if is_reasoning_model else "æ¨ç†"
                logger.info(f"AngelHeartåˆ†æå™¨: Promptæ¨¡å—ç»„è£…æˆåŠŸï¼Œä½¿ç”¨ {output_type} ç‰ˆæœ¬ã€‚")
            else:
                self.is_ready = False
                logger.critical("AngelHeartåˆ†æå™¨: Promptæ¨¡å—ç»„è£…å¤±è´¥ï¼Œæœªç”Ÿæˆæœ‰æ•ˆæ¨¡æ¿ã€‚åˆ†æå™¨å°†æ— æ³•å·¥ä½œã€‚")
        except Exception as e:
            self.is_ready = False
            logger.critical(f"AngelHeartåˆ†æå™¨: Promptæ¨¡å—ç»„è£…æ—¶å‘ç”Ÿé”™è¯¯: {e}ã€‚åˆ†æå™¨å°†æ— æ³•å·¥ä½œã€‚")

        if not self.analyzer_model_name:
            logger.warning("AngelHeartçš„åˆ†ææ¨¡å‹æœªé…ç½®ï¼ŒåŠŸèƒ½å°†å—é™ã€‚")

    def reload_config(self, new_config_manager):
        """é‡æ–°åŠ è½½é…ç½®"""
        self.config_manager = new_config_manager

        # é‡æ–°åŠ è½½æç¤ºè¯æ¨¡å—
        try:
            self.prompt_loader.reload_modules()
            is_reasoning_model = new_config_manager.is_reasoning_model if new_config_manager else False
            self.base_prompt_template = self.prompt_loader.build_prompt_template(is_reasoning_model)

            if self.base_prompt_template:
                self.is_ready = True
                output_type = "æŒ‡ä»¤" if is_reasoning_model else "æ¨ç†"
                logger.info(f"AngelHeartåˆ†æå™¨: Promptæ¨¡æ¿é‡æ–°åŠ è½½æˆåŠŸï¼Œä½¿ç”¨ {output_type} ç‰ˆæœ¬ã€‚")
            else:
                self.is_ready = False
                logger.warning("AngelHeartåˆ†æå™¨: Promptæ¨¡æ¿é‡æ–°åŠ è½½å¤±è´¥ï¼Œåˆ†æå™¨æœªå°±ç»ªã€‚")
        except Exception as e:
            self.is_ready = False
            logger.error(f"AngelHeartåˆ†æå™¨: Promptæ¨¡æ¿é‡æ–°åŠ è½½æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    def _parse_response(self, response_text: str, alias: str) -> SecretaryDecision:
        """
        è§£æAIæ¨¡å‹çš„å“åº”æ–‡æœ¬å¹¶è¿”å›SecretaryDecisionå¯¹è±¡

        Args:
            response_text (str): AIæ¨¡å‹çš„å“åº”æ–‡æœ¬
            alias (str): AIçš„æ˜µç§°

        Returns:
            SecretaryDecision: è§£æåçš„å†³ç­–å¯¹è±¡
        """
        return self._parse_and_validate_decision(response_text, alias)

    async def _call_ai_model(self, prompt: str, chat_id: str) -> str:
        """
        è°ƒç”¨AIæ¨¡å‹å¹¶è¿”å›å“åº”æ–‡æœ¬ï¼ŒåŒ…å«3ç§’åè‡ªåŠ¨é‡è¯•1æ¬¡æœºåˆ¶
        """
        # 3. å¦‚æœå¯ç”¨äº†æç¤ºè¯æ—¥å¿—å¢å¼ºï¼Œåˆ™è®°å½•æœ€ç»ˆæ„å»ºçš„å®Œæ•´æç¤ºè¯
        if False:  # prompt_logging_enabled å·²åºŸå¼ƒ
            logger.info(
                f"[AngelHeart][{chat_id}]:æœ€ç»ˆæ„å»ºçš„å®Œæ•´æç¤ºè¯ ----------------"
            )
            logger.info(prompt)
            logger.info("----------------------------------------")

        # åŠ¨æ€è·å– provider
        provider = self.context.get_provider_by_id(self.analyzer_model_name)
        if not provider:
            logger.warning(
                f"AngelHeartåˆ†æå™¨: æœªæ‰¾åˆ°åä¸º '{self.analyzer_model_name}' çš„åˆ†ææ¨¡å‹æä¾›å•†ã€‚"
            )
            raise Exception("æœªæ‰¾åˆ°åˆ†ææ¨¡å‹æä¾›å•†")

        # é‡è¯•æœºåˆ¶ï¼šæœ€å¤šé‡è¯•1æ¬¡ï¼Œé—´éš”3ç§’
        max_retries = 1
        retry_delay = 3  # ç§’

        for attempt in range(max_retries + 1):
            try:
                token = await provider.text_chat(prompt=prompt)
                response_text = token.completion_text.strip()

                # è®°å½•AIæ¨¡å‹çš„å®Œæ•´å“åº”å†…å®¹
                logger.debug(
                    f"[AngelHeart][{chat_id}]: è½»é‡æ¨¡å‹çš„åˆ†ææ¨ç† ----------------"
                )
                logger.debug(response_text)
                logger.debug("----------------------------------------")

                return response_text

            except Exception as e:
                if attempt < max_retries:
                    logger.warning(
                        f"AngelHeartåˆ†æå™¨: ç¬¬{attempt + 1}æ¬¡è°ƒç”¨AIæ¨¡å‹å¤±è´¥ï¼Œ{retry_delay}ç§’åé‡è¯•: {e}"
                    )
                    await asyncio.sleep(retry_delay)
                else:
                    logger.error(
                        f"ğŸ’¥ AngelHeartåˆ†æå™¨: è°ƒç”¨AIæ¨¡å‹å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {e}",
                        exc_info=True,
                    )
                    raise

    def _build_prompt(
        self, historical_context: List[Dict], recent_dialogue: List[Dict]
    ) -> str:
        """
        ä½¿ç”¨ç»™å®šçš„å¯¹è¯å†å²æ„å»ºåˆ†ææç¤ºè¯

        Args:
            conversations (List[Dict]): å¯¹è¯å†å²

        Returns:
            str: æ„å»ºå¥½çš„æç¤ºè¯
        """
        # åˆ†åˆ«æ ¼å¼åŒ–å†å²ä¸Šä¸‹æ–‡å’Œæœ€è¿‘å¯¹è¯
        historical_text = self._format_conversation_history(historical_context)
        recent_text = self._format_conversation_history(recent_dialogue)

        # å¢å¼ºæ£€æŸ¥ï¼šå¦‚æœå†å²æ–‡æœ¬ä¸ºç©ºï¼Œåˆ™è®°å½•è­¦å‘Šæ—¥å¿—
        if not historical_text and not recent_text:
            logger.warning(
                "AngelHeartåˆ†æå™¨: æ ¼å¼åŒ–åçš„å¯¹è¯å†å²ä¸ºç©ºï¼Œå°†ç”Ÿæˆä¸€ä¸ªç©ºçš„åˆ†ææç¤ºè¯ã€‚"
            )

        # è·å–é…ç½®ä¸­çš„æ˜µç§°
        alias = self.config_manager.alias if self.config_manager else "AngelHeart"

        # ä½¿ç”¨ç›´æ¥çš„å­—ç¬¦ä¸²æ›¿æ¢æ¥æ„å»ºæç¤ºè¯ï¼Œè§„é¿.format()æ–¹æ³•å¯¹ç‰¹æ®Šå­—ç¬¦çš„è§£æé—®é¢˜
        base_prompt = self.base_prompt_template
        base_prompt = base_prompt.replace("{historical_context}", historical_text)
        base_prompt = base_prompt.replace("{recent_dialogue}", recent_text)
        base_prompt = base_prompt.replace("{reply_strategy_guide}", self.strategy_guide)
        base_prompt = base_prompt.replace("{alias}", alias)
        base_prompt = base_prompt.replace(
            "{ai_self_identity}",
            self.config_manager.ai_self_identity if self.config_manager else "",
        )

        return base_prompt

    async def analyze_and_decide(
        self, historical_context: List[Dict], recent_dialogue: List[Dict], chat_id: str
    ) -> SecretaryDecision:
        """
        åˆ†æå¯¹è¯å†å²ï¼Œåšå‡ºç»“æ„åŒ–çš„å†³ç­– (JSON)
        """
        # è·å–æ˜µç§°
        alias = self.config_manager.alias if self.config_manager else "AngelHeart"

        if not self.analyzer_model_name:
            logger.debug("AngelHeartåˆ†æå™¨: åˆ†ææ¨¡å‹æœªé…ç½®, è·³è¿‡åˆ†æã€‚")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„ä¸å‚ä¸å†³ç­–
            return SecretaryDecision(
                should_reply=False, reply_strategy="æœªé…ç½®", topic="æœªçŸ¥", alias=alias
            )

        if not self.is_ready:
            logger.debug("AngelHeartåˆ†æå™¨: ç”±äºæ ¸å¿ƒPromptæ¨¡æ¿ä¸¢å¤±ï¼Œåˆ†æå™¨å·²ç¦ç”¨ã€‚")
            return SecretaryDecision(
                should_reply=False,
                reply_strategy="åˆ†æå™¨æœªå°±ç»ª",
                topic="æœªçŸ¥",
                alias=alias,
            )

        # 1. è°ƒç”¨è½»é‡çº§AIè¿›è¡Œåˆ†æ
        logger.debug("AngelHeartåˆ†æå™¨: å‡†å¤‡è°ƒç”¨è½»é‡çº§AIè¿›è¡Œåˆ†æ...")
        prompt = self._build_prompt(historical_context, recent_dialogue)

        # 2. å¢å¼ºæ£€æŸ¥ï¼šå¦‚æœç”Ÿæˆçš„æç¤ºè¯ä¸ºç©ºï¼Œåˆ™è®°å½•è­¦å‘Šæ—¥å¿—å¹¶è¿”å›ä¸€ä¸ªæ˜ç¡®çš„å†³ç­–
        if not prompt:
            logger.warning(
                "AngelHeartåˆ†æå™¨: ç”Ÿæˆçš„åˆ†ææç¤ºè¯ä¸ºç©ºï¼Œå°†è¿”å›'åˆ†æå†…å®¹ä¸ºç©º'çš„å†³ç­–ã€‚"
            )
            return SecretaryDecision(
                should_reply=False,
                reply_strategy="åˆ†æå†…å®¹ä¸ºç©º",
                topic="æœªçŸ¥",
                alias=alias,
            )

        response_text = ""
        try:
            response_text = await self._call_ai_model(prompt, chat_id)
            # è°ƒç”¨æ–°æ–¹æ³•è§£æå’ŒéªŒè¯å“åº”ï¼Œå¹¶ä¼ é€’ alias
            return self._parse_response(response_text, alias)
        except (json.JSONDecodeError, KeyError) as e:
            logger.warning(
                f"AngelHeartåˆ†æå™¨: AIè¿”å›çš„JSONæ ¼å¼æˆ–å†…å®¹æœ‰è¯¯: {e}. åŸå§‹å“åº”: {response_text[:200]}..."
            )
        except asyncio.CancelledError:
            # é‡æ–°æŠ›å‡º CancelledErrorï¼Œä»¥ç¡®ä¿å¼‚æ­¥ä»»åŠ¡å¯ä»¥è¢«æ­£å¸¸å–æ¶ˆ
            raise
        except Exception as e:
            logger.error(
                f"ğŸ’¥ AngelHeartåˆ†æå™¨: è½»é‡çº§AIåˆ†æå¤±è´¥: {e}",
                exc_info=True,
            )

        # å¦‚æœå‘ç”Ÿä»»ä½•é”™è¯¯ï¼Œéƒ½è¿”å›ä¸€ä¸ªé»˜è®¤çš„ä¸å‚ä¸å†³ç­–
        return SecretaryDecision(
            should_reply=False, reply_strategy="åˆ†æå¤±è´¥", topic="æœªçŸ¥", alias=alias
        )

    def _parse_and_validate_decision(
        self, response_text: str, alias: str
    ) -> SecretaryDecision:
        """è§£æå¹¶éªŒè¯æ¥è‡ªAIçš„å“åº”æ–‡æœ¬ï¼Œæ„å»ºSecretaryDecisionå¯¹è±¡"""

        # å®šä¹‰SecretaryDecisionçš„å­—æ®µè¦æ±‚
        required_fields = ["should_reply", "reply_strategy", "topic", "reply_target"]
        optional_fields = ["needs_search", "is_questioned", "is_interesting"]

        # ä½¿ç”¨JsonParseræå–JSONæ•°æ®
        try:
            decision_data = self.json_parser.extract_json(
                text=response_text,
                required_fields=required_fields,
                optional_fields=optional_fields,
            )
        except Exception as e:
            logger.warning(
                f"AngelHeartåˆ†æå™¨: JsonParseræå–JSONæ—¶å‘ç”Ÿå¼‚å¸¸: {e}. åŸå§‹å“åº”: {response_text[:200]}..."
            )
            decision_data = None

        # å¦‚æœJsonParseræœªèƒ½æå–åˆ°æœ‰æ•ˆçš„JSON
        if decision_data is None:
            logger.warning(
                f"AngelHeartåˆ†æå™¨: JsonParseræ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSONã€‚åŸå§‹å“åº”: {response_text[:200]}..."
            )
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„ä¸å‚ä¸å†³ç­–
            return SecretaryDecision(
                should_reply=False,
                reply_strategy="åˆ†æå†…å®¹æ— æœ‰æ•ˆJSON",
                topic="æœªçŸ¥",
                alias=alias,
            )

        # å¯¹æ¥è‡ª AI çš„ JSON åšå¥å£®æ€§å¤„ç†ï¼Œé˜²æ­¢å­—æ®µä¸º null æˆ–ç±»å‹ä¸ç¬¦åˆå¯¼è‡´ pydantic æ ¡éªŒå¤±è´¥
        raw = decision_data
        # è§£æ should_replyï¼Œå…¼å®¹ boolã€æ•°å­—ã€å­—ç¬¦ä¸²ç­‰å½¢å¼
        should_reply_raw = raw.get("should_reply", False)
        if isinstance(should_reply_raw, bool):
            should_reply = should_reply_raw
        elif isinstance(should_reply_raw, (int, float)):
            should_reply = bool(should_reply_raw)
        elif isinstance(should_reply_raw, str):
            should_reply = should_reply_raw.lower() in ("true", "1", "yes", "æ˜¯", "å¯¹")
        else:
            should_reply = False

        # è§£æ is_questioned
        is_questioned_raw = raw.get("is_questioned", False)
        if isinstance(is_questioned_raw, bool):
            is_questioned = is_questioned_raw
        elif isinstance(is_questioned_raw, (int, float)):
            is_questioned = bool(is_questioned_raw)
        elif isinstance(is_questioned_raw, str):
            is_questioned = is_questioned_raw.lower() in (
                "true",
                "1",
                "yes",
                "æ˜¯",
                "å¯¹",
            )
        else:
            is_questioned = False

        # è§£æ is_interesting
        is_interesting_raw = raw.get("is_interesting", False)
        if isinstance(is_interesting_raw, bool):
            is_interesting = is_interesting_raw
        elif isinstance(is_interesting_raw, (int, float)):
            is_interesting = bool(is_interesting_raw)
        elif isinstance(is_interesting_raw, str):
            is_interesting = is_interesting_raw.lower() in (
                "true",
                "1",
                "yes",
                "æ˜¯",
                "å¯¹",
            )
        else:
            is_interesting = False

        # æå–å…¶ä»–å­—æ®µ
        reply_strategy = str(raw.get("reply_strategy") or "æœªçŸ¥ç­–ç•¥")
        topic = str(raw.get("topic") or "æœªçŸ¥è¯é¢˜")
        reply_target = str(raw.get("reply_target") or "")

        # åˆ›å»ºå†³ç­–å¯¹è±¡
        decision = SecretaryDecision(
            should_reply=should_reply,
            is_questioned=is_questioned,
            is_interesting=is_interesting,
            reply_strategy=reply_strategy,
            topic=topic,
            reply_target=reply_target,
            alias=alias,
        )

        # ä»£ç æ ¡éªŒå’Œä¿®æ­£é€»è¾‘
        if (
            decision.should_reply
            and not decision.is_questioned
            and not decision.is_interesting
        ):
            logger.warning(
                "AngelHeartåˆ†æå™¨: AIåˆ¤æ–­æœ‰çŸ›ç›¾ - should_reply=true ä½†æ²¡æœ‰è§¦å‘åŸå› ï¼Œå¼ºåˆ¶è®¾ä¸ºä¸å›å¤"
            )
            decision.should_reply = False
            decision.reply_strategy = "ç»§ç»­è§‚å¯Ÿ"

        return decision

    def _format_conversation_history(self, conversations: List[Dict]) -> str:
        """
        æ ¼å¼åŒ–å¯¹è¯å†å²ï¼Œç”Ÿæˆç»Ÿä¸€çš„æ—¥å¿—å¼æ ¼å¼ã€‚

        Args:
            conversations (List[Dict]): åŒ…å«å¯¹è¯å†å²çš„å­—å…¸åˆ—è¡¨ã€‚

        Returns:
            str: æ ¼å¼åŒ–åçš„å¯¹è¯å†å²å­—ç¬¦ä¸²ã€‚
        """
        # Phase 3: å¢åŠ ç©ºæ•°æ®ä¿æŠ¤æœºåˆ¶ - å¼€å§‹
        # é˜²æ­¢ç©ºæ•°æ®å¯¼è‡´å´©æºƒçš„ä¿æŠ¤æœºåˆ¶
        if not conversations:
            return ""
        # Phase 3: å¢åŠ ç©ºæ•°æ®ä¿æŠ¤æœºåˆ¶ - ç»“æŸ

        lines = []
        # å®šä¹‰å†å²ä¸æ–°æ¶ˆæ¯çš„åˆ†éš”ç¬¦å¯¹è±¡
        SEPARATOR_OBJ = {"role": "system", "content": "history_separator"}

        # éå†æœ€è¿‘çš„ MAX_CONVERSATION_LENGTH æ¡å¯¹è¯
        for conv in conversations[-self.MAX_CONVERSATION_LENGTH :]:
            # ç¡®ä¿ conv æ˜¯ä¸€ä¸ªå­—å…¸
            if not isinstance(conv, dict):
                logger.warning(f"è·³è¿‡éå­—å…¸ç±»å‹çš„å¯¹è¯é¡¹: {type(conv)}")
                continue

            # æ£€æŸ¥æ˜¯å¦é‡åˆ°åˆ†éš”ç¬¦
            if conv == SEPARATOR_OBJ:
                lines.append("\n--- ä»¥ä¸Šæ˜¯å†å²æ¶ˆæ¯ï¼Œä»…ä½œä¸ºç­–ç•¥å‚è€ƒï¼Œä¸éœ€è¦å›åº” ---\n")
                lines.append(
                    "\n--- åç»­çš„æœ€æ–°å¯¹è¯ï¼Œä½ éœ€è¦åˆ†è¾¨å‡ºé‡Œé¢çš„äººæ˜¯ä¸æ˜¯åœ¨å¯¹ä½ è¯´è¯ ---\n"
                )
                continue  # è·³è¿‡åˆ†éš”ç¬¦æœ¬èº«ï¼Œä¸æ·»åŠ åˆ°æœ€ç»ˆè¾“å‡º

            # ä½¿ç”¨æ–°çš„è¾…åŠ©æ–¹æ³•æ ¼å¼åŒ–å•æ¡æ¶ˆæ¯
            formatted_message = self._format_single_message(conv)
            lines.append(formatted_message)

        # å°†æ‰€æœ‰æ ¼å¼åŒ–åçš„è¡Œè¿æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²å¹¶è¿”å›
        return "\n".join(lines)

    def _format_single_message(self, conv: Dict) -> str:
        """
        æ ¼å¼åŒ–å•æ¡æ¶ˆæ¯ï¼Œç”Ÿæˆç»Ÿä¸€çš„æ—¥å¿—å¼æ ¼å¼ã€‚

        Args:
            conv (Dict): åŒ…å«æ¶ˆæ¯ä¿¡æ¯çš„å­—å…¸ã€‚

        Returns:
            str: æ ¼å¼åŒ–åçš„æ¶ˆæ¯å­—ç¬¦ä¸²ã€‚
        """
        role = conv.get("role")
        content = conv.get("content", "")

        if role == "assistant":
            # åŠ©ç†æ¶ˆæ¯æ ¼å¼: [åŠ©ç†]\n[å†…å®¹: æ–‡æœ¬]\n{content}
            formatted_content = convert_content_to_string(content)
            return f"[åŠ©ç†]\n[å†…å®¹: æ–‡æœ¬]\n{formatted_content}"
        elif role == "user":
            # ç”¨æˆ·æ¶ˆæ¯éœ€è¦åŒºåˆ†æ¥æº
            # æ£€æŸ¥æ˜¯å¦åŒ…å«sender_nameå­—æ®µï¼Œè¿™é€šå¸¸æ„å‘³ç€æ¥è‡ªFrontDeskçš„ç¼“å­˜æ¶ˆæ¯
            if "sender_name" in conv:
                # æ¥è‡ªç¼“å­˜çš„æ–°æ¶ˆæ¯
                sender_id = conv.get("sender_id", "Unknown")
                sender_name = conv.get("sender_name", "æˆå‘˜")
                timestamp = conv.get("timestamp")
                relative_time_str = format_relative_time(timestamp)
                formatted_content = convert_content_to_string(content)

                # æ–°æ ¼å¼: [ç¾¤å‹: æ˜µç§° (ID: ...)] (ç›¸å¯¹æ—¶é—´)\n[å†…å®¹: ç±»å‹]\nå®é™…å†…å®¹
                header = f"[ç¾¤å‹: {sender_name} (ID: {sender_id})]{relative_time_str}"

                # ç®€å•åˆ¤æ–­å†…å®¹ç±»å‹ï¼Œè¿™é‡Œå¯ä»¥æ›´å¤æ‚
                content_type = "æ–‡æœ¬"
                if isinstance(content, str) and content.startswith("[å›¾ç‰‡]"):
                    content_type = "å›¾ç‰‡"
                elif isinstance(content, list):
                    # å¦‚æœcontentæ˜¯åˆ—è¡¨ï¼Œconvert_content_to_stringä¼šå¤„ç†æˆå­—ç¬¦ä¸²
                    # æˆ‘ä»¬å¯ä»¥æ£€æŸ¥è½¬æ¢åçš„å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«[å›¾ç‰‡]
                    temp_str = convert_content_to_string(content)
                    if "[å›¾ç‰‡]" in temp_str:
                        content_type = "å›¾ç‰‡"

                return f"{header}\n[å†…å®¹: {content_type}]\n{formatted_content}"
            else:
                # æ¥è‡ªæ•°æ®åº“çš„å†å²æ¶ˆæ¯
                formatted_content = convert_content_to_string(content)
                # å†å²æ¶ˆæ¯æ ¼å¼: [ç¾¤å‹: (å†å²è®°å½•)]\n[å†…å®¹: ç±»å‹]\nå®é™…å†…å®¹
                header = "[ç¾¤å‹: (å†å²è®°å½•)]"

                # åŒæ ·åˆ¤æ–­å†…å®¹ç±»å‹
                content_type = "æ–‡æœ¬"
                if isinstance(formatted_content, str) and "[å›¾ç‰‡]" in formatted_content:
                    content_type = "å›¾ç‰‡"

                return f"{header}\n[å†…å®¹: {content_type}]\n{formatted_content}"
        else:
            # å¯¹äºå…¶ä»–è§’è‰²ï¼ˆå¦‚systemç­‰ï¼‰ï¼Œå¯ä»¥è€ƒè™‘è·³è¿‡æˆ–ç»™äºˆé»˜è®¤åç§°
            # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ç»™ä¸€ä¸ªé€šç”¨åç§°
            formatted_content = convert_content_to_string(content)
            return f"[{role}]\n[å†…å®¹: æ–‡æœ¬]\n{formatted_content}"
